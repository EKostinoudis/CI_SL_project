{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.mnist import read_data\n",
    "import numpy as np\n",
    "from utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "FIG_FOLDER = 'kpca/mnist'\n",
    "SAVE_PLOTS = True # save all the plots\n",
    "# SAVE_PLOTS = False # save all the plots\n",
    "DTYPE = np.float32\n",
    "wanted_freq = 1200 # number of samples per class\n",
    "wanted_freq2 = 700 # number of samples per class for the training, rest for validation\n",
    "\n",
    "# figure size\n",
    "plt.rcParams[\"figure.figsize\"] = (10,8)\n",
    "\n",
    "# load the data\n",
    "chose_split = False # load all the data and then chose how to split\n",
    "if chose_split:\n",
    "    X, y = read_data.load_all_data()\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1337)\n",
    "    del X # save some space\n",
    "    del y # save some space\n",
    "else:\n",
    "    # load the training and testing sets as given by the author\n",
    "    x_train, y_train = read_data.load_train_data()\n",
    "    x_test, y_test = read_data.load_test_data()\n",
    "\n",
    "# serialize images (from 2d to 1d)\n",
    "x_train = x_train.reshape((x_train.shape[0], -1))\n",
    "x_test = x_test.reshape((x_test.shape[0], -1))\n",
    "\n",
    "# test = True # for testing stuff without the need to wait an eternity\n",
    "test = False # for testing stuff without the need to wait an eternity\n",
    "if test:\n",
    "    wanted_freq = 400\n",
    "    wanted_freq2 = 150\n",
    "    # x_train = x_train[:2000]\n",
    "    # y_train = y_train[:2000]\n",
    "    x_test = x_test[:800]\n",
    "    y_test = y_test[:800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train).astype(DTYPE)\n",
    "x_test = scaler.transform(x_test).astype(DTYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsample training data in order to equalize class frequencies\n",
    "# we match the lowest class frequency\n",
    "vals, freq = np.unique(y_train, return_counts = True)\n",
    "# wanted_freq = min(freq)\n",
    "all_indexes = np.zeros((len(freq), wanted_freq), dtype=np.uint32)\n",
    "for i, v in enumerate(vals):\n",
    "    indexes = np.random.choice(np.where(y_train == v)[0], size=wanted_freq, replace=False)\n",
    "    all_indexes[i, :] = indexes\n",
    "all_indexes = np.sort(all_indexes.flatten())\n",
    "y_train = y_train[all_indexes]\n",
    "x_train = x_train[all_indexes, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals2, freq2 = np.unique(y_train, return_counts = True)\n",
    "x_ = np.arange(len(freq))\n",
    "width = 0.45\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(15,12))\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(x_ - width/2, freq, width, label='Original Training Set')\n",
    "ax.bar(x_ + width/2, freq2, width, label='Subsampled Training Set')\n",
    "ax.set_ylabel('Number of samples')\n",
    "ax.set_xlabel('Class')\n",
    "ax.set_title('Training set balance')\n",
    "ax.set_xticks(x_)\n",
    "ax.set_xticklabels(vals)\n",
    "ax.legend()\n",
    "plt.show()\n",
    "if SAVE_PLOTS:\n",
    "    save_plots(fig, 'training_freq', FIG_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hold wanted_freq2 samples per class for training and the rest of the\n",
    "# training set for validation\n",
    "x_train_all = x_train\n",
    "y_train_all = y_train\n",
    "\n",
    "all_indexes = np.zeros((len(freq), wanted_freq2), dtype=np.uint32)\n",
    "for i, v in enumerate(vals):\n",
    "    indexes = np.random.choice(np.where(y_train == v)[0], size=wanted_freq2, replace=False)\n",
    "    all_indexes[i, :] = indexes\n",
    "all_indexes = np.sort(all_indexes.flatten())\n",
    "y_train = y_train_all[all_indexes]\n",
    "x_train = x_train_all[all_indexes, :]\n",
    "validation_indexes = np.delete(np.arange(y_train_all.shape[0]), all_indexes)\n",
    "y_val = y_train_all[validation_indexes]\n",
    "x_val = x_train_all[validation_indexes, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kpca_plus_lda import KPCA_LDA\n",
    "\n",
    "\n",
    "params = [\n",
    "          {'kernel': 'linear'},\n",
    "          {'kernel': 'poly', 'degree': 2, 'gamma': 0.1},\n",
    "          {'kernel': 'poly', 'degree': 2, 'gamma': 1},\n",
    "          {'kernel': 'poly', 'degree': 2, 'gamma': 10},\n",
    "\n",
    "          # {'kernel': 'rbf', 'gamma': 0.001},\n",
    "          # {'kernel': 'rbf', 'gamma': 0.005},\n",
    "          {'kernel': 'rbf', 'gamma': 0.01},\n",
    "          {'kernel': 'rbf', 'gamma': 0.1},\n",
    "          {'kernel': 'rbf', 'gamma': 1},\n",
    "\n",
    "          {'kernel': 'sigmoid', 'gamma': 0.00001},\n",
    "          {'kernel': 'sigmoid', 'gamma': 0.0001},\n",
    "          {'kernel': 'sigmoid', 'gamma': 0.001},\n",
    "         ]\n",
    "\n",
    "# models = [KPCA_LDA(**kwargs) for kwargs in params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from time import time\n",
    "\n",
    "neighbors = [1, 3, 5, 10, 15]\n",
    "\n",
    "times, metrics_knn, metrics_nc = [], [], []\n",
    "for kwargs in params:\n",
    "    t0 = time()\n",
    "    model = KPCA_LDA(**kwargs)\n",
    "    dist, z_train = model.fit(x_train, y_train, return_z=True)\n",
    "    dist_val, z_val = model.transform(x_val, return_z=True)\n",
    "    t1 = time()\n",
    "\n",
    "    knn_metrics = []\n",
    "    for n in neighbors:\n",
    "        knn = KNeighborsClassifier(n_neighbors=n, metric='precomputed')\n",
    "        knn.fit(dist, y_train)\n",
    "        metrics = calculate_metrics(knn, dist_val, y_val)\n",
    "        knn_metrics.append(metrics)\n",
    "    t2 = time()\n",
    "\n",
    "    nc = NearestCentroid()\n",
    "    nc.fit(z_train, y_train)\n",
    "    t3 = time()\n",
    "\n",
    "    nc_val_metrics = calculate_metrics(nc, z_val, y_val)\n",
    "\n",
    "    times.append((t0, t1, t2, t3))\n",
    "    metrics_knn.append(knn_metrics)\n",
    "    metrics_nc.append(nc_val_metrics)\n",
    "\n",
    "    print(f'{model.kernel}: {metrics[0]:.4f} | {nc_val_metrics[0]:.4f}')\n",
    "    print(f'KPCA+LDA: {t1-t0:.4f}, KNN: {t2-t1:.4f}, nc: {t3-t2:.4f}, total: {t3-t0:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results\n",
    "import pandas as pd\n",
    "\n",
    "save_folder = f'results/{FIG_FOLDER}/'\n",
    "create_if_not_exists(save_folder)\n",
    "\n",
    "# create the names for the models\n",
    "names = []\n",
    "for p in params:\n",
    "    names.append(\"\\n\".join([f'{key}: {val}' for key, val in p.items()]))\n",
    "\n",
    "kpca_lda_time = []\n",
    "nc_times = []\n",
    "for t in times:\n",
    "    kpca_lda_time.append(t[1] - t[0])\n",
    "    nc_times.append(t[3] - t[2])\n",
    "\n",
    "# save nc data\n",
    "data = zip(names, *(np.array(metrics_nc).T), kpca_lda_time, nc_times)\n",
    "col_names = [\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\", \"KPCA+LDA Time (seconds)\", \"Nearest Centroid Time\"]\n",
    "df = pd.DataFrame(data, columns=col_names)\n",
    "df.to_excel(save_folder+'nc_validation.xlsx', float_format=\"%.4f\", index=False)\n",
    "df.to_csv(save_folder+'nc_validation.csv', float_format=\"%.4f\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_knn = np.array([[n[0] for n in m] for m in metrics_knn])\n",
    "best_idxes = np.argmax(acc_knn, axis=1)\n",
    "best_n_knn = np.array(neighbors)[best_idxes]\n",
    "\n",
    "# save knn data\n",
    "data = zip(names, best_n_knn, *(np.array(metrics_knn)[np.arange(len(metrics_knn)), best_idxes].T))\n",
    "col_names = [\"Model\", \"Best n\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\"]\n",
    "df = pd.DataFrame(data, columns=col_names)\n",
    "df.to_excel(save_folder+'knn_validation.xlsx', float_format=\"%.4f\", index=False)\n",
    "df.to_csv(save_folder+'knn_validation.csv', float_format=\"%.4f\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mm, m, p in zip(metrics_knn, metrics_nc, params):\n",
    "    print(p, m[0], mm[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_knn = np.array([[n[0] for n in m] for m in metrics_knn])\n",
    "best_model, best_n = np.unravel_index(np.argmax(acc_knn, axis=None), acc_knn.shape)\n",
    "print(f'Best knn model: {params[best_model]} | Best n: {neighbors[best_n]} | accuracy: {acc_knn[best_model][best_n]}')\n",
    "\n",
    "acc_nc = np.array([n[0] for n in metrics_nc])\n",
    "best_model_nc = np.argmax(acc_nc)\n",
    "print(f'Best nc model: {params[best_model_nc]} | accuracy: {acc_nc[best_model_nc]}')\n",
    "\n",
    "best_model_knn = best_model\n",
    "best_model = best_model_nc if acc_knn[best_model][best_n] < acc_nc[best_model_nc] else best_model_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "thetas = [0.5, 0.8, 1, 1.3, 1.5, 1.8]\n",
    "theta_metrics = []\n",
    "model = KPCA_LDA(**params[best_model])\n",
    "dist = model.fit(x_train, y_train)\n",
    "for theta in thetas:\n",
    "    t0 = time()\n",
    "    dist = model.train_dist(theta=theta)\n",
    "    dist_val = model.transform(x_val)\n",
    "    t1 = time()\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=neighbors[best_n], metric='precomputed')\n",
    "    knn.fit(dist, y_train)\n",
    "    metrics = calculate_metrics(knn, dist_val, y_val)\n",
    "    theta_metrics.append(metrics)\n",
    "    t2 = time()\n",
    "\n",
    "    print(f'{theta}: {metrics[0]:.4f}')\n",
    "    print(f'KPCA+LDA: {t1-t0:.4f}, KNN: {t2-t1:.4f}, total: {t2-t0:.4f}')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "acc_thetas = np.array([n[0] for n in theta_metrics])\n",
    "best_theta_idx = np.argmax(acc_thetas)\n",
    "print(f'Best theta: {thetas[best_theta_idx]} | accuracy: {acc_thetas[best_theta_idx]}')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the best model with all the training data\n",
    "x_train = x_train_all\n",
    "y_train = y_train_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KPCA plus LDA\n",
    "t0 = time()\n",
    "# model = KPCA_LDA(theta=thetas[best_theta_idx], **params[best_model])\n",
    "model = KPCA_LDA(**params[best_model])\n",
    "dist, z_train = model.fit(x_train, y_train, return_z=True)\n",
    "dist_test, z_test = model.transform(x_test, return_z=True)\n",
    "t1 = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_1 = time()\n",
    "knn = KNeighborsClassifier(n_neighbors=neighbors[best_n], metric='precomputed')\n",
    "knn.fit(dist, y_train)\n",
    "metrics = calculate_metrics(knn, dist_test, y_test)\n",
    "metrics_train = calculate_metrics(knn, dist, y_train)\n",
    "t2 = time()\n",
    "\n",
    "nc = NearestCentroid()\n",
    "nc.fit(z_train, y_train)\n",
    "t3 = time()\n",
    "\n",
    "nc_test_metrics = calculate_metrics(nc, z_test, y_test)\n",
    "nc_train_metrics = calculate_metrics(nc, z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results\n",
    "name = \"\\n\".join([f'{key}: {val}' for key, val in (params[best_model]).items()])\n",
    "data = [[name, *nc_train_metrics, t1-t0, t3-t2]]\n",
    "col_names = [\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\", \"KPCA+LDA Time (seconds)\", \"Nearest Centroid Time\"]\n",
    "df = pd.DataFrame(data, columns=col_names)\n",
    "df.to_excel(save_folder+'nc_final_train.xlsx', float_format=\"%.4f\", index=False)\n",
    "df.to_csv(save_folder+'nc_final_train.csv', float_format=\"%.4f\", index=False)\n",
    "\n",
    "data = [[name, *nc_test_metrics, t1-t0, t3-t2]]\n",
    "col_names = [\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\", \"KPCA+LDA Time (seconds)\", \"Nearest Centroid Time\"]\n",
    "df = pd.DataFrame(data, columns=col_names)\n",
    "df.to_excel(save_folder+'nc_final_test.xlsx', float_format=\"%.4f\", index=False)\n",
    "df.to_csv(save_folder+'nc_final_test.csv', float_format=\"%.4f\", index=False)\n",
    "\n",
    "data = [[name, neighbors[best_n], *metrics_train, t1-t0, t2-t1_1]]\n",
    "col_names = [\"Model\", \"Best n\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\", \"KPCA+LDA Time (seconds)\", \"kNN Time\"]\n",
    "df = pd.DataFrame(data, columns=col_names)\n",
    "df.to_excel(save_folder+'knn_final_train.xlsx', float_format=\"%.4f\", index=False)\n",
    "df.to_csv(save_folder+'knn_final_train.csv', float_format=\"%.4f\", index=False)\n",
    "\n",
    "data = [[name, neighbors[best_n], *metrics, t1-t0, t2-t1_1]]\n",
    "col_names = [\"Model\", \"Best n\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\", \"KPCA+LDA Time (seconds)\", \"kNN Time\"]\n",
    "df = pd.DataFrame(data, columns=col_names)\n",
    "df.to_excel(save_folder+'knn_final_test.xlsx', float_format=\"%.4f\", index=False)\n",
    "df.to_csv(save_folder+'knn_final_test.csv', float_format=\"%.4f\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_train, nc_train_metrics, metrics, nc_test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "label_names = list(range(10))\n",
    "best_name = \" \".join([f'{key}: {val}' for key, val in (params[best_model]).items()])\n",
    "\n",
    "pred_knn = knn.predict(dist_test)\n",
    "\n",
    "# fig = plt.figure(figsize=(15,12))\n",
    "fig = plt.figure()\n",
    "ax = sns.heatmap(confusion_matrix(y_test, pred_knn), annot=True, cmap='Purples', fmt='g')\n",
    "\n",
    "ax.set_title(f'Confusion Matrix | kNN: {neighbors[best_n]} neighbors | {best_name}')\n",
    "ax.set_xlabel('Predictions')\n",
    "ax.set_ylabel('Actual Values')\n",
    "# ax.xaxis.set_ticklabels(label_names, rotation=90)\n",
    "ax.xaxis.set_ticklabels(label_names, rotation=0)\n",
    "ax.yaxis.set_ticklabels(label_names, rotation=0)\n",
    "\n",
    "plt.show()\n",
    "if SAVE_PLOTS:\n",
    "    save_plots(fig, 'confusion_matrix_knn', FIG_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_nc = nc.predict(z_test)\n",
    "\n",
    "# fig = plt.figure(figsize=(15,12))\n",
    "fig = plt.figure()\n",
    "ax = sns.heatmap(confusion_matrix(y_test, pred_nc), annot=True, cmap='Purples', fmt='g')\n",
    "\n",
    "ax.set_title(f'Confusion Matrix | Nearest Centroid | {best_name}')\n",
    "ax.set_xlabel('Predictions')\n",
    "ax.set_ylabel('Actual Values')\n",
    "# ax.xaxis.set_ticklabels(label_names, rotation=90)\n",
    "ax.xaxis.set_ticklabels(label_names, rotation=0)\n",
    "ax.yaxis.set_ticklabels(label_names, rotation=0)\n",
    "\n",
    "plt.show()\n",
    "if SAVE_PLOTS:\n",
    "    save_plots(fig, 'confusion_matrix_nc', FIG_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "\n",
    "# print wrong classifications\n",
    "wrong_classifications = np.where((pred_knn ^ y_test) != 0)[0]\n",
    "wrong_classes, wrong_idxs = np.unique(y_test[wrong_classifications], return_index=True)\n",
    "\n",
    "x_test, _ = read_data.load_test_data()\n",
    "\n",
    "# wrong_images = pipe.inverse_transform(x_test[wrong_classifications[wrong_idxs], :]).reshape(-1,28,28)\n",
    "wrong_images = x_test[wrong_classifications[wrong_idxs], :]\n",
    "\n",
    "nrows, ncols = ceil(len(wrong_idxs) / 3), 3\n",
    "    \n",
    "fig, ax = plt.subplots(nrows, ncols, figsize=(9,7))\n",
    "# fig, ax = plt.subplots(nrows, ncols)\n",
    "for i, image in enumerate(wrong_images):\n",
    "    ax[i//ncols, i%ncols].imshow(image, cmap='gray', vmin=0, vmax=255)\n",
    "    ax[i//ncols, i%ncols].set_title(f'Predicted: {pred_knn[wrong_classifications[wrong_idxs[i]]]}, Actual: {y_test[wrong_classifications[wrong_idxs[i]]]}')\n",
    "\n",
    "# remove all axis\n",
    "for i in range(nrows):\n",
    "    for j in range(ncols):\n",
    "        ax[i,j].axis('off')\n",
    "plt.show()\n",
    "if SAVE_PLOTS:\n",
    "    save_plots(fig, 'wrong_results_knn_1', FIG_FOLDER)\n",
    "\n",
    "# remove previous images, so we don't display them twice\n",
    "wrong_classifications = np.delete(wrong_classifications, wrong_idxs)\n",
    "\n",
    "wrong_classes, wrong_idxs = np.unique(pred_knn[wrong_classifications], return_index=True)\n",
    "wrong_images = x_test[wrong_classifications[wrong_idxs], :]\n",
    "\n",
    "nrows, ncols = ceil(len(wrong_idxs) / 3), 3\n",
    "\n",
    "if nrows > 1:\n",
    "    fig, ax = plt.subplots(nrows, ncols, figsize=(9,7))\n",
    "    # fig, ax = plt.subplots(nrows, ncols)\n",
    "    for i, image in enumerate(wrong_images):\n",
    "        ax[i//ncols, i%ncols].imshow(image, cmap='gray', vmin=0, vmax=255)\n",
    "        ax[i//ncols, i%ncols].set_title(f'Predicted: {pred_knn[wrong_classifications[wrong_idxs[i]]]}, Actual: {y_test[wrong_classifications[wrong_idxs[i]]]}')\n",
    "\n",
    "    # remove all axis\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            ax[i,j].axis('off')\n",
    "    plt.show()\n",
    "    if SAVE_PLOTS:\n",
    "        save_plots(fig, 'wrong_results_knn_2', FIG_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print wrong classifications\n",
    "wrong_classifications = np.where((pred_nc ^ y_test) != 0)[0]\n",
    "wrong_classes, wrong_idxs = np.unique(y_test[wrong_classifications], return_index=True)\n",
    "\n",
    "x_test, _ = read_data.load_test_data()\n",
    "\n",
    "# wrong_images = pipe.inverse_transform(x_test[wrong_classifications[wrong_idxs], :]).reshape(-1,28,28)\n",
    "wrong_images = x_test[wrong_classifications[wrong_idxs], :]\n",
    "\n",
    "nrows, ncols = ceil(len(wrong_idxs) / 3), 3\n",
    "    \n",
    "fig, ax = plt.subplots(nrows, ncols, figsize=(9,7))\n",
    "# fig, ax = plt.subplots(nrows, ncols)\n",
    "for i, image in enumerate(wrong_images):\n",
    "    ax[i//ncols, i%ncols].imshow(image, cmap='gray', vmin=0, vmax=255)\n",
    "    ax[i//ncols, i%ncols].set_title(f'Predicted: {pred_nc[wrong_classifications[wrong_idxs[i]]]}, Actual: {y_test[wrong_classifications[wrong_idxs[i]]]}')\n",
    "\n",
    "# remove all axis\n",
    "for i in range(nrows):\n",
    "    for j in range(ncols):\n",
    "        ax[i,j].axis('off')\n",
    "plt.show()\n",
    "if SAVE_PLOTS:\n",
    "    save_plots(fig, 'wrong_results_nc_1', FIG_FOLDER)\n",
    "\n",
    "# remove previous images, so we don't display them twice\n",
    "wrong_classifications = np.delete(wrong_classifications, wrong_idxs)\n",
    "\n",
    "wrong_classes, wrong_idxs = np.unique(pred_nc[wrong_classifications], return_index=True)\n",
    "wrong_images = x_test[wrong_classifications[wrong_idxs], :]\n",
    "\n",
    "nrows, ncols = ceil(len(wrong_idxs) / 3), 3\n",
    "\n",
    "if nrows > 1:\n",
    "    fig, ax = plt.subplots(nrows, ncols, figsize=(9,7))\n",
    "    # fig, ax = plt.subplots(nrows, ncols)\n",
    "    for i, image in enumerate(wrong_images):\n",
    "        ax[i//ncols, i%ncols].imshow(image, cmap='gray', vmin=0, vmax=255)\n",
    "        ax[i//ncols, i%ncols].set_title(f'Predicted: {pred_nc[wrong_classifications[wrong_idxs[i]]]}, Actual: {y_test[wrong_classifications[wrong_idxs[i]]]}')\n",
    "\n",
    "    # remove all axis\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            ax[i,j].axis('off')\n",
    "    plt.show()\n",
    "    if SAVE_PLOTS:\n",
    "        save_plots(fig, 'wrong_results_nc_2', FIG_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_samples=2500, n_features=20, n_classes=5, n_informative=5, n_redundant=5,n_repeated=0, shuffle=True, random_state=42)\n",
    "x_train = X[:200,:]\n",
    "x_val = X[200:,:]\n",
    "y_train = y[:200]\n",
    "y_val = y[200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = KPCA_LDA(kernel='rbf', gamma=0.001)\n",
    "dist = model.fit(x_train, y_train)\n",
    "dist_val = model.transform(x_val)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3, metric='precomputed')\n",
    "knn.fit(dist, y_train)\n",
    "pred = knn.predict(dist_val)\n",
    "# metrics = calculate_metrics(knn, dist_val, y_val)\n",
    "print(accuracy_score(y_val, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = KPCA_LDA(kernel='rbf', gamma=0.01)\n",
    "dist = model.fit(x_train, y_train)\n",
    "dist_test = model.transform(x_test)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3, metric='precomputed')\n",
    "knn.fit(dist, y_train)\n",
    "pred = knn.predict(dist_test)\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.metrics import accuracy_score\n",
    "from time import time\n",
    "\n",
    "# TODO: hold best model\n",
    "for kwargs in params:\n",
    "    t0 = time()\n",
    "    model = KPCA_LDA(**kwargs)\n",
    "    dist, z_train = model.fit(x_train, y_train, return_z=True)\n",
    "    dist_test, z_test = model.transform(x_test, return_z=True)\n",
    "    t1 = time()\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=3, metric='precomputed')\n",
    "    knn.fit(dist, y_train)\n",
    "    metrics = calculate_metrics(knn, dist_test, y_test)\n",
    "    t2 = time()\n",
    "\n",
    "    nc = NearestCentroid()\n",
    "    t3 = time()\n",
    "    nc.fit(z_train, y_train)\n",
    "    nc_time = time() - t3\n",
    "    # nc_train_metrics = calculate_metrics(nc, x_train, y_train)\n",
    "    nc_test_metrics = calculate_metrics(nc, z_test, y_test)\n",
    "\n",
    "    print(f'{model.kernel}: {metrics} | {nc_test_metrics}')\n",
    "    print(f'KPCA+LDA: {t1-t0}, KNN: {t2-t1}, total: {t2-t0}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for theta in [0.5, 0.8, 1, 1.1, 1.2, 1.3, 1.5, 1.8]:\n",
    "    t0 = time()\n",
    "    model = KPCA_LDA(kernel='rbf', theta=theta, gamma=0.01)\n",
    "    dist = model.fit(x_train, y_train)\n",
    "    dist_test = model.transform(x_test)\n",
    "    t1 = time()\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=3, metric='precomputed')\n",
    "    knn.fit(dist, y_train)\n",
    "    metrics = calculate_metrics(knn, dist_test, y_test)\n",
    "    t2 = time()\n",
    "    print(f'{theta}: {metrics}')\n",
    "    print(f'KPCA+LDA: {t1-t0}, KNN: {t2-t1}, total: {t2-t0}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "model = KPCA_LDA(kernel='rbf', gamma=0.01)\n",
    "dist = model.fit(x_train, y_train)\n",
    "dist_test = model.transform(x_test)\n",
    "t1 = time()\n",
    "\n",
    "for n in [1,2,3,4,5,8,10,15,20]:\n",
    "    knn = KNeighborsClassifier(n_neighbors=n, metric='precomputed')\n",
    "    knn.fit(dist, y_train)\n",
    "    metrics = calculate_metrics(knn, dist_test, y_test)\n",
    "    t2 = time()\n",
    "    print(f'{n}: {metrics}')\n",
    "    print(f'KPCA+LDA: {t1-t0}, KNN: {t2-t1}, total: {t2-t0}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpca = KPCA(kernel='linear', theta=1.2, gamma=0.1)\n",
    "x_new = kpca.fit(x_train, y_train)\n",
    "x_test2 = kpca.transform(x_test)\n",
    "\n",
    "kpca = KPCA(kernel='poly', theta=1.2, gamma=0.1)\n",
    "x_new = kpca.fit(x_train, y_train)\n",
    "x_test2 = kpca.transform(x_test)\n",
    "\n",
    "kpca = KPCA(kernel='sigmoid', theta=1.2, gamma=0.1)\n",
    "x_new = kpca.fit(x_train, y_train)\n",
    "x_test2 = kpca.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "def pairplot(x, y):\n",
    "    df = pd.DataFrame(np.concatenate((x, y.reshape(-1,1)), axis=1), columns=list(range(x.shape[1]+1)))\n",
    "\n",
    "    sns.pairplot(df, hue=x.shape[1])\n",
    "    plt.show()\n",
    "# pairplot(x_test2, y_test)\n",
    "pairplot(x_new, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairplot(x_new, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "# from sklearn.lda import LDA\n",
    "\n",
    "kpca2 = KernelPCA(kernel='rbf',gamma=.1)\n",
    "x_train2 = kpca2.fit_transform(x_train)\n",
    "lda = LDA()\n",
    "x_new2 = lda.fit_transform(x_train2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_new = lda.transform(kpca2.transform(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairplot(x_new2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairplot(x_test_new, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.DataFrame(np.concatenate((x_new2, y_train.reshape(-1,1)), axis=1), columns=list(range(x_new2.shape[1]+1)))\n",
    "\n",
    "sns.pairplot(df, hue=x_new2.shape[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot new training data\n",
    "for j in range(1,9):\n",
    "    plt.Figure()\n",
    "    '''\n",
    "    for i in range(10):\n",
    "        plt.scatter(x_new[y_train==i, 1], x_new[y_train==i, 2], label=i)\n",
    "    '''\n",
    "    plt.scatter(x_new2[:, 0], x_new2[:, j], c=y_train)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot new training data\n",
    "for j in range(1,18):\n",
    "    plt.Figure()\n",
    "    '''\n",
    "    for i in range(10):\n",
    "        plt.scatter(x_new[y_train==i, 1], x_new[y_train==i, 2], label=i)\n",
    "    '''\n",
    "    plt.scatter(x_new[:, 0], x_new[:, j], c=y_train)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.Figure()\n",
    "for i in range(10):\n",
    "    plt.scatter(x_train[y_train==i, 100], x_train[y_train==i, 80], label=i)\n",
    "# plt.scatter(x_new[:, 0], x_new[:, 1], c=y_train)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "dist = distance.cdist(x_new2, x_new2, metric='sqeuclidean')\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=1, metric='precomputed')\n",
    "knn.fit(dist, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist2 = distance.cdist(x_test_new, x_new2, metric='sqeuclidean')\n",
    "knn.predict(dist2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# kpca+lda from sklearn\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(x_new2, y_train)\n",
    "pred = knn.predict(x_test_new)\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# MINE kpca+lda\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(x_new, y_train)\n",
    "pred = knn.predict(x_test2)\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "knn = KNeighborsClassifier(n_neighbors=3, metric='precomputed')\n",
    "knn.fit(x_new, y_train)\n",
    "pred = knn.predict(x_test2)\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
